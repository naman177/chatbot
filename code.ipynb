{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "from __future__ import division, print_function\n",
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu import config\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu.model import Metadata, Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "def train_nlu(data, configs, model_dir):\n",
    "    training_data = load_data(data)\n",
    "    trainer = Trainer(config.load(configs))\n",
    "    trainer.train(training_data)\n",
    "    model_directory = trainer.persist(model_dir,fixed_model_name='recruitment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELLPC~1\\Desktop\\PUSHPN~1\\CDACTR~1\\rasa123\\lib\\site-packages\\rasa_nlu\\classifiers\\embedding_intent_classifier.py:285: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\DELLPC~1\\Desktop\\PUSHPN~1\\CDACTR~1\\rasa123\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DELLPC~1\\Desktop\\PUSHPN~1\\CDACTR~1\\rasa123\\lib\\site-packages\\rasa_nlu\\classifiers\\embedding_intent_classifier.py:286: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From C:\\Users\\DELLPC~1\\Desktop\\PUSHPN~1\\CDACTR~1\\rasa123\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\DELLPC~1\\Desktop\\PUSHPN~1\\CDACTR~1\\rasa123\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\DELLPC~1\\Desktop\\PUSHPN~1\\CDACTR~1\\rasa123\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|█████████████████████████████████████████████████| 300/300 [00:08<00:00, 35.26it/s, loss=0.102, acc=0.970]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_nlu('data/data.md', 'config.json', 'models/nlu/new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELLPC~1\\Desktop\\PUSHPN~1\\CDACTR~1\\rasa123\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n",
      "{'intent': {'name': 'goodbye', 'confidence': 0.9541353583335876}, 'entities': [], 'intent_ranking': [{'name': 'goodbye', 'confidence': 0.9541353583335876}, {'name': 'name', 'confidence': 0.16464078426361084}, {'name': 'tech', 'confidence': 0.13565102219581604}, {'name': 'deny', 'confidence': 0.03245767951011658}, {'name': 'greet', 'confidence': 0.0}, {'name': 'thanks', 'confidence': 0.0}, {'name': 'greet+name+status', 'confidence': 0.0}, {'name': 'emotions', 'confidence': 0.0}, {'name': 'contact', 'confidence': 0.0}, {'name': 'status', 'confidence': 0.0}], 'text': 'bye'}\n"
     ]
    }
   ],
   "source": [
    "interpreter = Interpreter.load('./models/nlu/new/default/recruitment')\n",
    "\n",
    "# testing\n",
    "print(interpreter.parse(\"bye\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import logging\n",
    "import rasa_core\n",
    "\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.policies.keras_policy import KerasPolicy\n",
    "from rasa_core.policies.memoization import MemoizationPolicy\n",
    "from rasa_core.interpreter import RasaNLUInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "from rasa_core.run import serve_application\n",
    "from rasa_core import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed Story Blocks: 100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 165.03it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 70.62it/s, # trackers=10]\n",
      "Processed Story Blocks: 100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 64.56it/s, # trackers=13]\n",
      "Processed Story Blocks: 100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 54.69it/s, # trackers=12]\n",
      "Processed actions: 143it [00:00, 328.27it/s, # examples=143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 46)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                10112     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 25)                825       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 25)                0         \n",
      "=================================================================\n",
      "Total params: 10,937\n",
      "Trainable params: 10,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "814/814 [==============================] - ETA: 37s - loss: 3.1404 - acc: 0.06 - ETA: 8s - loss: 3.1436 - acc: 0.0469 - ETA: 3s - loss: 3.1271 - acc: 0.069 - ETA: 1s - loss: 3.0933 - acc: 0.117 - ETA: 0s - loss: 3.0519 - acc: 0.164 - 2s 2ms/sample - loss: 3.0358 - acc: 0.1769\n",
      "Epoch 2/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 2.8217 - acc: 0.312 - ETA: 0s - loss: 2.7922 - acc: 0.325 - ETA: 0s - loss: 2.7357 - acc: 0.328 - ETA: 0s - loss: 2.7123 - acc: 0.329 - ETA: 0s - loss: 2.6869 - acc: 0.326 - 0s 305us/sample - loss: 2.6855 - acc: 0.3243\n",
      "Epoch 3/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 2.4819 - acc: 0.312 - ETA: 0s - loss: 2.4765 - acc: 0.324 - ETA: 0s - loss: 2.4430 - acc: 0.325 - ETA: 0s - loss: 2.4415 - acc: 0.319 - 0s 284us/sample - loss: 2.4421 - acc: 0.3157\n",
      "Epoch 4/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 2.3335 - acc: 0.312 - ETA: 0s - loss: 2.3161 - acc: 0.343 - ETA: 0s - loss: 2.3203 - acc: 0.315 - ETA: 0s - loss: 2.3050 - acc: 0.325 - 0s 285us/sample - loss: 2.3090 - acc: 0.3194\n",
      "Epoch 5/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 2.1987 - acc: 0.312 - ETA: 0s - loss: 2.2031 - acc: 0.332 - ETA: 0s - loss: 2.1843 - acc: 0.332 - ETA: 0s - loss: 2.1943 - acc: 0.338 - 0s 265us/sample - loss: 2.1938 - acc: 0.3354\n",
      "Epoch 6/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 2.1089 - acc: 0.406 - ETA: 0s - loss: 2.1068 - acc: 0.343 - ETA: 0s - loss: 2.0929 - acc: 0.337 - ETA: 0s - loss: 2.0858 - acc: 0.343 - 0s 262us/sample - loss: 2.0876 - acc: 0.3403\n",
      "Epoch 7/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.9610 - acc: 0.468 - ETA: 0s - loss: 1.9989 - acc: 0.383 - ETA: 0s - loss: 1.9872 - acc: 0.362 - ETA: 0s - loss: 1.9733 - acc: 0.369 - ETA: 0s - loss: 1.9708 - acc: 0.368 - 0s 299us/sample - loss: 1.9566 - acc: 0.3722\n",
      "Epoch 8/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.8649 - acc: 0.437 - ETA: 0s - loss: 1.8826 - acc: 0.406 - ETA: 0s - loss: 1.8680 - acc: 0.377 - ETA: 0s - loss: 1.8216 - acc: 0.396 - 0s 272us/sample - loss: 1.8334 - acc: 0.3919\n",
      "Epoch 9/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.7302 - acc: 0.468 - ETA: 0s - loss: 1.7456 - acc: 0.418 - ETA: 0s - loss: 1.7420 - acc: 0.410 - ETA: 0s - loss: 1.7197 - acc: 0.422 - ETA: 0s - loss: 1.7240 - acc: 0.422 - 0s 309us/sample - loss: 1.7230 - acc: 0.4251\n",
      "Epoch 10/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.6673 - acc: 0.500 - ETA: 0s - loss: 1.6368 - acc: 0.437 - ETA: 0s - loss: 1.6188 - acc: 0.446 - ETA: 0s - loss: 1.6041 - acc: 0.459 - 0s 266us/sample - loss: 1.6108 - acc: 0.4521\n",
      "Epoch 11/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.5545 - acc: 0.437 - ETA: 0s - loss: 1.5552 - acc: 0.479 - ETA: 0s - loss: 1.5176 - acc: 0.480 - ETA: 0s - loss: 1.4960 - acc: 0.494 - ETA: 0s - loss: 1.5144 - acc: 0.489 - 0s 315us/sample - loss: 1.5123 - acc: 0.4889\n",
      "Epoch 12/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.5371 - acc: 0.531 - ETA: 0s - loss: 1.4775 - acc: 0.495 - ETA: 0s - loss: 1.4501 - acc: 0.509 - ETA: 0s - loss: 1.4208 - acc: 0.528 - ETA: 0s - loss: 1.4223 - acc: 0.527 - 0s 287us/sample - loss: 1.4206 - acc: 0.5283\n",
      "Epoch 13/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.4941 - acc: 0.531 - ETA: 0s - loss: 1.4117 - acc: 0.531 - ETA: 0s - loss: 1.3799 - acc: 0.549 - ETA: 0s - loss: 1.3420 - acc: 0.567 - 0s 261us/sample - loss: 1.3552 - acc: 0.5614\n",
      "Epoch 14/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.3922 - acc: 0.531 - ETA: 0s - loss: 1.3449 - acc: 0.544 - ETA: 0s - loss: 1.3155 - acc: 0.568 - ETA: 0s - loss: 1.2759 - acc: 0.590 - ETA: 0s - loss: 1.2836 - acc: 0.593 - 0s 309us/sample - loss: 1.2817 - acc: 0.5934\n",
      "Epoch 15/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.3346 - acc: 0.625 - ETA: 0s - loss: 1.2217 - acc: 0.628 - ETA: 0s - loss: 1.2025 - acc: 0.647 - ETA: 0s - loss: 1.1894 - acc: 0.647 - 0s 261us/sample - loss: 1.1962 - acc: 0.6376\n",
      "Epoch 16/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.3277 - acc: 0.593 - ETA: 0s - loss: 1.1656 - acc: 0.665 - ETA: 0s - loss: 1.1584 - acc: 0.675 - ETA: 0s - loss: 1.1529 - acc: 0.662 - 0s 273us/sample - loss: 1.1525 - acc: 0.6622\n",
      "Epoch 17/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.2428 - acc: 0.625 - ETA: 0s - loss: 1.1408 - acc: 0.674 - ETA: 0s - loss: 1.0980 - acc: 0.706 - ETA: 0s - loss: 1.0883 - acc: 0.707 - 0s 263us/sample - loss: 1.0920 - acc: 0.6978\n",
      "Epoch 18/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.3031 - acc: 0.562 - ETA: 0s - loss: 1.0633 - acc: 0.707 - ETA: 0s - loss: 1.0397 - acc: 0.727 - ETA: 0s - loss: 1.0367 - acc: 0.720 - ETA: 0s - loss: 1.0337 - acc: 0.727 - 0s 301us/sample - loss: 1.0296 - acc: 0.7297\n",
      "Epoch 19/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.0867 - acc: 0.718 - ETA: 0s - loss: 0.9788 - acc: 0.761 - ETA: 0s - loss: 0.9775 - acc: 0.764 - ETA: 0s - loss: 0.9504 - acc: 0.773 - 0s 263us/sample - loss: 0.9507 - acc: 0.7752\n",
      "Epoch 20/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 1.0406 - acc: 0.750 - ETA: 0s - loss: 0.9304 - acc: 0.744 - ETA: 0s - loss: 0.9060 - acc: 0.778 - ETA: 0s - loss: 0.9029 - acc: 0.787 - ETA: 0s - loss: 0.8983 - acc: 0.782 - 0s 324us/sample - loss: 0.9046 - acc: 0.7813\n",
      "Epoch 21/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.9890 - acc: 0.750 - ETA: 0s - loss: 0.8573 - acc: 0.789 - ETA: 0s - loss: 0.8490 - acc: 0.805 - ETA: 0s - loss: 0.8223 - acc: 0.815 - ETA: 0s - loss: 0.8392 - acc: 0.807 - 0s 284us/sample - loss: 0.8379 - acc: 0.8084\n",
      "Epoch 22/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.9256 - acc: 0.781 - ETA: 0s - loss: 0.8029 - acc: 0.835 - ETA: 0s - loss: 0.7795 - acc: 0.837 - ETA: 0s - loss: 0.7777 - acc: 0.833 - 0s 252us/sample - loss: 0.7770 - acc: 0.8354\n",
      "Epoch 23/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.8330 - acc: 0.812 - ETA: 0s - loss: 0.7227 - acc: 0.831 - ETA: 0s - loss: 0.7492 - acc: 0.823 - ETA: 0s - loss: 0.7133 - acc: 0.841 - ETA: 0s - loss: 0.7207 - acc: 0.838 - 0s 298us/sample - loss: 0.7152 - acc: 0.8391\n",
      "Epoch 24/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.8489 - acc: 0.750 - ETA: 0s - loss: 0.7116 - acc: 0.825 - ETA: 0s - loss: 0.6998 - acc: 0.841 - ETA: 0s - loss: 0.6608 - acc: 0.850 - ETA: 0s - loss: 0.6745 - acc: 0.847 - 0s 301us/sample - loss: 0.6699 - acc: 0.8464\n",
      "Epoch 25/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.7888 - acc: 0.812 - ETA: 0s - loss: 0.6532 - acc: 0.853 - ETA: 0s - loss: 0.6292 - acc: 0.869 - ETA: 0s - loss: 0.6339 - acc: 0.859 - 0s 272us/sample - loss: 0.6339 - acc: 0.8563\n",
      "Epoch 26/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.843 - ETA: 0s - loss: 0.6100 - acc: 0.838 - ETA: 0s - loss: 0.5993 - acc: 0.875 - ETA: 0s - loss: 0.5720 - acc: 0.887 - ETA: 0s - loss: 0.5940 - acc: 0.881 - 0s 286us/sample - loss: 0.5872 - acc: 0.8808\n",
      "Epoch 27/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.7679 - acc: 0.843 - ETA: 0s - loss: 0.5719 - acc: 0.875 - ETA: 0s - loss: 0.5523 - acc: 0.896 - ETA: 0s - loss: 0.5501 - acc: 0.892 - 0s 251us/sample - loss: 0.5474 - acc: 0.8919\n",
      "Epoch 28/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.6821 - acc: 0.812 - ETA: 0s - loss: 0.5802 - acc: 0.838 - ETA: 0s - loss: 0.5419 - acc: 0.875 - ETA: 0s - loss: 0.5214 - acc: 0.889 - 0s 252us/sample - loss: 0.5184 - acc: 0.8907\n",
      "Epoch 29/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.5659 - acc: 0.875 - ETA: 0s - loss: 0.4888 - acc: 0.899 - ETA: 0s - loss: 0.4730 - acc: 0.912 - ETA: 0s - loss: 0.4677 - acc: 0.915 - 0s 255us/sample - loss: 0.4719 - acc: 0.9152\n",
      "Epoch 30/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.5855 - acc: 0.843 - ETA: 0s - loss: 0.4425 - acc: 0.906 - ETA: 0s - loss: 0.4428 - acc: 0.902 - ETA: 0s - loss: 0.4491 - acc: 0.898 - 0s 229us/sample - loss: 0.4472 - acc: 0.8993\n",
      "Epoch 31/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.4823 - acc: 0.843 - ETA: 0s - loss: 0.4032 - acc: 0.910 - ETA: 0s - loss: 0.4097 - acc: 0.920 - ETA: 0s - loss: 0.4028 - acc: 0.924 - 0s 240us/sample - loss: 0.4037 - acc: 0.9226\n",
      "Epoch 32/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.4675 - acc: 0.875 - ETA: 0s - loss: 0.4168 - acc: 0.923 - ETA: 0s - loss: 0.3994 - acc: 0.928 - ETA: 0s - loss: 0.4029 - acc: 0.921 - 0s 251us/sample - loss: 0.4012 - acc: 0.9189\n",
      "Epoch 33/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.4249 - acc: 0.875 - ETA: 0s - loss: 0.3789 - acc: 0.921 - ETA: 0s - loss: 0.3586 - acc: 0.933 - ETA: 0s - loss: 0.3586 - acc: 0.936 - 0s 231us/sample - loss: 0.3572 - acc: 0.9373\n",
      "Epoch 34/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.4880 - acc: 0.843 - ETA: 0s - loss: 0.3639 - acc: 0.921 - ETA: 0s - loss: 0.3215 - acc: 0.941 - ETA: 0s - loss: 0.3418 - acc: 0.933 - 0s 231us/sample - loss: 0.3391 - acc: 0.9373\n",
      "Epoch 35/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.4271 - acc: 0.906 - ETA: 0s - loss: 0.3184 - acc: 0.937 - ETA: 0s - loss: 0.3262 - acc: 0.935 - ETA: 0s - loss: 0.3273 - acc: 0.931 - 0s 237us/sample - loss: 0.3233 - acc: 0.9337\n",
      "Epoch 36/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.4068 - acc: 0.843 - ETA: 0s - loss: 0.3144 - acc: 0.930 - ETA: 0s - loss: 0.2906 - acc: 0.944 - ETA: 0s - loss: 0.3024 - acc: 0.941 - 0s 221us/sample - loss: 0.3008 - acc: 0.9423\n",
      "Epoch 37/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.4035 - acc: 0.812 - ETA: 0s - loss: 0.3225 - acc: 0.895 - ETA: 0s - loss: 0.3005 - acc: 0.919 - ETA: 0s - loss: 0.2849 - acc: 0.932 - ETA: 0s - loss: 0.2937 - acc: 0.932 - 0s 291us/sample - loss: 0.2911 - acc: 0.9349\n",
      "Epoch 38/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.2447 - acc: 0.937 - ETA: 0s - loss: 0.2778 - acc: 0.937 - ETA: 0s - loss: 0.2705 - acc: 0.943 - ETA: 0s - loss: 0.2733 - acc: 0.945 - 0s 237us/sample - loss: 0.2720 - acc: 0.9459\n",
      "Epoch 39/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.3197 - acc: 0.906 - ETA: 0s - loss: 0.2466 - acc: 0.951 - ETA: 0s - loss: 0.2368 - acc: 0.961 - ETA: 0s - loss: 0.2452 - acc: 0.956 - 0s 250us/sample - loss: 0.2430 - acc: 0.9558\n",
      "Epoch 40/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.2893 - acc: 0.875 - ETA: 0s - loss: 0.2529 - acc: 0.946 - ETA: 0s - loss: 0.2250 - acc: 0.954 - 0s 201us/sample - loss: 0.2325 - acc: 0.9545\n",
      "Epoch 41/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.3314 - acc: 0.906 - ETA: 0s - loss: 0.2218 - acc: 0.944 - ETA: 0s - loss: 0.2220 - acc: 0.950 - ETA: 0s - loss: 0.2361 - acc: 0.940 - 0s 227us/sample - loss: 0.2348 - acc: 0.9410\n",
      "Epoch 42/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.3039 - acc: 0.843 - ETA: 0s - loss: 0.2363 - acc: 0.937 - ETA: 0s - loss: 0.2212 - acc: 0.944 - ETA: 0s - loss: 0.2184 - acc: 0.950 - 0s 225us/sample - loss: 0.2177 - acc: 0.9509\n",
      "Epoch 43/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.2553 - acc: 0.937 - ETA: 0s - loss: 0.2141 - acc: 0.950 - ETA: 0s - loss: 0.2171 - acc: 0.950 - ETA: 0s - loss: 0.2121 - acc: 0.953 - 0s 248us/sample - loss: 0.2117 - acc: 0.9509\n",
      "Epoch 44/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.2535 - acc: 0.906 - ETA: 0s - loss: 0.1924 - acc: 0.961 - ETA: 0s - loss: 0.1941 - acc: 0.964 - ETA: 0s - loss: 0.2044 - acc: 0.962 - 0s 234us/sample - loss: 0.2020 - acc: 0.9631\n",
      "Epoch 45/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1865 - acc: 0.937 - ETA: 0s - loss: 0.1843 - acc: 0.964 - ETA: 0s - loss: 0.1861 - acc: 0.964 - ETA: 0s - loss: 0.1945 - acc: 0.960 - 0s 246us/sample - loss: 0.1900 - acc: 0.9607\n",
      "Epoch 46/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.2066 - acc: 0.937 - ETA: 0s - loss: 0.1975 - acc: 0.962 - ETA: 0s - loss: 0.1762 - acc: 0.966 - ETA: 0s - loss: 0.1834 - acc: 0.965 - 0s 227us/sample - loss: 0.1839 - acc: 0.9656\n",
      "Epoch 47/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.2292 - acc: 0.906 - ETA: 0s - loss: 0.1675 - acc: 0.965 - ETA: 0s - loss: 0.1653 - acc: 0.962 - ETA: 0s - loss: 0.1838 - acc: 0.953 - 0s 239us/sample - loss: 0.1778 - acc: 0.9570\n",
      "Epoch 48/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1751 - acc: 0.968 - ETA: 0s - loss: 0.1794 - acc: 0.964 - ETA: 0s - loss: 0.1647 - acc: 0.966 - ETA: 0s - loss: 0.1626 - acc: 0.970 - 0s 245us/sample - loss: 0.1631 - acc: 0.9668\n",
      "Epoch 49/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1580 - acc: 0.937 - ETA: 0s - loss: 0.1389 - acc: 0.968 - ETA: 0s - loss: 0.1469 - acc: 0.970 - ETA: 0s - loss: 0.1553 - acc: 0.964 - 0s 247us/sample - loss: 0.1529 - acc: 0.9668\n",
      "Epoch 50/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1119 - acc: 1.000 - ETA: 0s - loss: 0.1445 - acc: 0.982 - ETA: 0s - loss: 0.1498 - acc: 0.975 - ETA: 0s - loss: 0.1561 - acc: 0.965 - 0s 246us/sample - loss: 0.1522 - acc: 0.9681\n",
      "Epoch 51/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1664 - acc: 0.937 - ETA: 0s - loss: 0.1546 - acc: 0.959 - ETA: 0s - loss: 0.1391 - acc: 0.961 - 0s 208us/sample - loss: 0.1458 - acc: 0.9619\n",
      "Epoch 52/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1737 - acc: 0.937 - ETA: 0s - loss: 0.1406 - acc: 0.975 - ETA: 0s - loss: 0.1383 - acc: 0.972 - ETA: 0s - loss: 0.1428 - acc: 0.967 - 0s 232us/sample - loss: 0.1408 - acc: 0.9681\n",
      "Epoch 53/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1465 - acc: 0.968 - ETA: 0s - loss: 0.1223 - acc: 0.986 - ETA: 0s - loss: 0.1178 - acc: 0.983 - ETA: 0s - loss: 0.1193 - acc: 0.980 - 0s 253us/sample - loss: 0.1224 - acc: 0.9803\n",
      "Epoch 54/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1477 - acc: 0.937 - ETA: 0s - loss: 0.1337 - acc: 0.978 - ETA: 0s - loss: 0.1211 - acc: 0.981 - ETA: 0s - loss: 0.1290 - acc: 0.975 - 0s 243us/sample - loss: 0.1278 - acc: 0.9754\n",
      "Epoch 55/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1250 - acc: 0.968 - ETA: 0s - loss: 0.1391 - acc: 0.965 - ETA: 0s - loss: 0.1265 - acc: 0.970 - ETA: 0s - loss: 0.1239 - acc: 0.973 - 0s 248us/sample - loss: 0.1251 - acc: 0.9717\n",
      "Epoch 56/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0769 - acc: 1.000 - ETA: 0s - loss: 0.1241 - acc: 0.977 - ETA: 0s - loss: 0.1160 - acc: 0.979 - ETA: 0s - loss: 0.1161 - acc: 0.978 - 0s 242us/sample - loss: 0.1145 - acc: 0.9791\n",
      "Epoch 57/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0906 - acc: 1.000 - ETA: 0s - loss: 0.1195 - acc: 0.979 - ETA: 0s - loss: 0.1205 - acc: 0.979 - ETA: 0s - loss: 0.1191 - acc: 0.977 - 0s 229us/sample - loss: 0.1158 - acc: 0.9791\n",
      "Epoch 58/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1311 - acc: 0.937 - ETA: 0s - loss: 0.1091 - acc: 0.968 - ETA: 0s - loss: 0.1082 - acc: 0.974 - ETA: 0s - loss: 0.1181 - acc: 0.970 - 0s 245us/sample - loss: 0.1154 - acc: 0.9717\n",
      "Epoch 59/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1398 - acc: 0.968 - ETA: 0s - loss: 0.0965 - acc: 0.984 - ETA: 0s - loss: 0.0909 - acc: 0.986 - 0s 203us/sample - loss: 0.1054 - acc: 0.9803\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814/814 [==============================] - ETA: 0s - loss: 0.1196 - acc: 0.968 - ETA: 0s - loss: 0.1143 - acc: 0.975 - ETA: 0s - loss: 0.1073 - acc: 0.975 - ETA: 0s - loss: 0.1114 - acc: 0.973 - 0s 259us/sample - loss: 0.1075 - acc: 0.9754\n",
      "Epoch 61/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1210 - acc: 0.937 - ETA: 0s - loss: 0.0962 - acc: 0.980 - ETA: 0s - loss: 0.0942 - acc: 0.983 - ETA: 0s - loss: 0.0917 - acc: 0.983 - 0s 257us/sample - loss: 0.0932 - acc: 0.9828\n",
      "Epoch 62/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1354 - acc: 0.968 - ETA: 0s - loss: 0.0965 - acc: 0.977 - ETA: 0s - loss: 0.0857 - acc: 0.979 - ETA: 0s - loss: 0.0947 - acc: 0.977 - 0s 250us/sample - loss: 0.0922 - acc: 0.9791\n",
      "Epoch 63/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1080 - acc: 0.968 - ETA: 0s - loss: 0.0799 - acc: 0.986 - ETA: 0s - loss: 0.0781 - acc: 0.986 - ETA: 0s - loss: 0.0873 - acc: 0.982 - 0s 262us/sample - loss: 0.0909 - acc: 0.9803\n",
      "Epoch 64/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0688 - acc: 1.000 - ETA: 0s - loss: 0.0796 - acc: 0.988 - ETA: 0s - loss: 0.0882 - acc: 0.985 - ETA: 0s - loss: 0.0922 - acc: 0.984 - 0s 232us/sample - loss: 0.0914 - acc: 0.9840\n",
      "Epoch 65/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.1105 - acc: 0.968 - ETA: 0s - loss: 0.0663 - acc: 0.988 - ETA: 0s - loss: 0.0749 - acc: 0.984 - ETA: 0s - loss: 0.0797 - acc: 0.985 - 0s 248us/sample - loss: 0.0813 - acc: 0.9816\n",
      "Epoch 66/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0559 - acc: 1.000 - ETA: 0s - loss: 0.0681 - acc: 0.984 - ETA: 0s - loss: 0.0748 - acc: 0.981 - ETA: 0s - loss: 0.0790 - acc: 0.981 - 0s 228us/sample - loss: 0.0803 - acc: 0.9816\n",
      "Epoch 67/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0879 - acc: 0.968 - ETA: 0s - loss: 0.0771 - acc: 0.980 - ETA: 0s - loss: 0.0744 - acc: 0.984 - ETA: 0s - loss: 0.0740 - acc: 0.982 - 0s 249us/sample - loss: 0.0751 - acc: 0.9816\n",
      "Epoch 68/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0576 - acc: 1.000 - ETA: 0s - loss: 0.0756 - acc: 0.982 - ETA: 0s - loss: 0.0770 - acc: 0.979 - ETA: 0s - loss: 0.0838 - acc: 0.978 - 0s 254us/sample - loss: 0.0803 - acc: 0.9791\n",
      "Epoch 69/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0329 - acc: 1.000 - ETA: 0s - loss: 0.0783 - acc: 0.975 - ETA: 0s - loss: 0.0774 - acc: 0.980 - ETA: 0s - loss: 0.0813 - acc: 0.977 - 0s 232us/sample - loss: 0.0794 - acc: 0.9791\n",
      "Epoch 70/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0888 - acc: 0.968 - ETA: 0s - loss: 0.0592 - acc: 0.988 - ETA: 0s - loss: 0.0685 - acc: 0.982 - ETA: 0s - loss: 0.0764 - acc: 0.979 - 0s 258us/sample - loss: 0.0719 - acc: 0.9816\n",
      "Epoch 71/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0866 - acc: 0.968 - ETA: 0s - loss: 0.0612 - acc: 0.988 - ETA: 0s - loss: 0.0645 - acc: 0.986 - ETA: 0s - loss: 0.0657 - acc: 0.985 - 0s 225us/sample - loss: 0.0661 - acc: 0.9853\n",
      "Epoch 72/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0411 - acc: 1.000 - ETA: 0s - loss: 0.0643 - acc: 0.979 - ETA: 0s - loss: 0.0695 - acc: 0.980 - ETA: 0s - loss: 0.0779 - acc: 0.977 - 0s 223us/sample - loss: 0.0756 - acc: 0.9791\n",
      "Epoch 73/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0870 - acc: 0.937 - ETA: 0s - loss: 0.0623 - acc: 0.980 - ETA: 0s - loss: 0.0645 - acc: 0.985 - ETA: 0s - loss: 0.0699 - acc: 0.985 - ETA: 0s - loss: 0.0672 - acc: 0.985 - 0s 280us/sample - loss: 0.0665 - acc: 0.9853\n",
      "Epoch 74/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0791 - acc: 0.968 - ETA: 0s - loss: 0.0616 - acc: 0.984 - ETA: 0s - loss: 0.0589 - acc: 0.985 - ETA: 0s - loss: 0.0654 - acc: 0.983 - 0s 240us/sample - loss: 0.0628 - acc: 0.9840\n",
      "Epoch 75/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0776 - acc: 0.968 - ETA: 0s - loss: 0.0624 - acc: 0.988 - ETA: 0s - loss: 0.0574 - acc: 0.990 - ETA: 0s - loss: 0.0651 - acc: 0.986 - 0s 247us/sample - loss: 0.0639 - acc: 0.9865\n",
      "Epoch 76/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0270 - acc: 1.000 - ETA: 0s - loss: 0.0730 - acc: 0.982 - ETA: 0s - loss: 0.0729 - acc: 0.981 - ETA: 0s - loss: 0.0709 - acc: 0.985 - 0s 218us/sample - loss: 0.0714 - acc: 0.9853\n",
      "Epoch 77/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0392 - acc: 1.000 - ETA: 0s - loss: 0.0681 - acc: 0.982 - ETA: 0s - loss: 0.0664 - acc: 0.984 - ETA: 0s - loss: 0.0692 - acc: 0.983 - 0s 233us/sample - loss: 0.0698 - acc: 0.9840\n",
      "Epoch 78/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0314 - acc: 1.000 - ETA: 0s - loss: 0.0812 - acc: 0.984 - ETA: 0s - loss: 0.0710 - acc: 0.980 - ETA: 0s - loss: 0.0729 - acc: 0.976 - 0s 252us/sample - loss: 0.0728 - acc: 0.9767\n",
      "Epoch 79/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0211 - acc: 1.000 - ETA: 0s - loss: 0.0595 - acc: 0.992 - ETA: 0s - loss: 0.0545 - acc: 0.991 - ETA: 0s - loss: 0.0642 - acc: 0.985 - 0s 255us/sample - loss: 0.0629 - acc: 0.9865\n",
      "Epoch 80/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0779 - acc: 0.968 - ETA: 0s - loss: 0.0538 - acc: 0.984 - ETA: 0s - loss: 0.0562 - acc: 0.980 - ETA: 0s - loss: 0.0593 - acc: 0.983 - 0s 241us/sample - loss: 0.0602 - acc: 0.9828\n",
      "Epoch 81/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0269 - acc: 1.000 - ETA: 0s - loss: 0.0432 - acc: 0.995 - ETA: 0s - loss: 0.0406 - acc: 0.997 - ETA: 0s - loss: 0.0489 - acc: 0.994 - 0s 254us/sample - loss: 0.0474 - acc: 0.9914\n",
      "Epoch 82/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0609 - acc: 1.000 - ETA: 0s - loss: 0.0512 - acc: 0.982 - ETA: 0s - loss: 0.0484 - acc: 0.980 - ETA: 0s - loss: 0.0555 - acc: 0.980 - 0s 258us/sample - loss: 0.0542 - acc: 0.9828\n",
      "Epoch 83/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0655 - acc: 0.968 - ETA: 0s - loss: 0.0662 - acc: 0.980 - ETA: 0s - loss: 0.0658 - acc: 0.980 - ETA: 0s - loss: 0.0651 - acc: 0.980 - 0s 256us/sample - loss: 0.0632 - acc: 0.9816\n",
      "Epoch 84/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0198 - acc: 1.000 - ETA: 0s - loss: 0.0640 - acc: 0.982 - ETA: 0s - loss: 0.0572 - acc: 0.983 - ETA: 0s - loss: 0.0583 - acc: 0.982 - 0s 211us/sample - loss: 0.0597 - acc: 0.9828\n",
      "Epoch 85/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0623 - acc: 0.968 - ETA: 0s - loss: 0.0415 - acc: 0.989 - ETA: 0s - loss: 0.0446 - acc: 0.991 - ETA: 0s - loss: 0.0490 - acc: 0.992 - 0s 277us/sample - loss: 0.0493 - acc: 0.9914\n",
      "Epoch 86/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0224 - acc: 1.000 - ETA: 0s - loss: 0.0576 - acc: 0.982 - ETA: 0s - loss: 0.0531 - acc: 0.983 - ETA: 0s - loss: 0.0530 - acc: 0.983 - 0s 235us/sample - loss: 0.0524 - acc: 0.9840\n",
      "Epoch 87/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0441 - acc: 1.000 - ETA: 0s - loss: 0.0426 - acc: 0.996 - ETA: 0s - loss: 0.0543 - acc: 0.988 - ETA: 0s - loss: 0.0542 - acc: 0.987 - 0s 229us/sample - loss: 0.0536 - acc: 0.9877\n",
      "Epoch 88/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0581 - acc: 0.968 - ETA: 0s - loss: 0.0563 - acc: 0.979 - ETA: 0s - loss: 0.0609 - acc: 0.981 - ETA: 0s - loss: 0.0602 - acc: 0.982 - 0s 225us/sample - loss: 0.0604 - acc: 0.9828\n",
      "Epoch 89/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0174 - acc: 1.000 - ETA: 0s - loss: 0.0469 - acc: 0.989 - ETA: 0s - loss: 0.0484 - acc: 0.985 - ETA: 0s - loss: 0.0494 - acc: 0.985 - 0s 227us/sample - loss: 0.0501 - acc: 0.9840\n",
      "Epoch 90/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0625 - acc: 0.968 - ETA: 0s - loss: 0.0455 - acc: 0.988 - ETA: 0s - loss: 0.0426 - acc: 0.988 - ETA: 0s - loss: 0.0451 - acc: 0.989 - 0s 235us/sample - loss: 0.0434 - acc: 0.9902\n",
      "Epoch 91/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0198 - acc: 1.000 - ETA: 0s - loss: 0.0424 - acc: 0.989 - ETA: 0s - loss: 0.0459 - acc: 0.987 - ETA: 0s - loss: 0.0447 - acc: 0.988 - 0s 259us/sample - loss: 0.0480 - acc: 0.9877\n",
      "Epoch 92/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0519 - acc: 0.968 - ETA: 0s - loss: 0.0527 - acc: 0.980 - ETA: 0s - loss: 0.0479 - acc: 0.983 - ETA: 0s - loss: 0.0503 - acc: 0.984 - 0s 241us/sample - loss: 0.0497 - acc: 0.9840\n",
      "Epoch 93/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0179 - acc: 1.000 - ETA: 0s - loss: 0.0404 - acc: 0.988 - ETA: 0s - loss: 0.0550 - acc: 0.981 - ETA: 0s - loss: 0.0552 - acc: 0.983 - 0s 235us/sample - loss: 0.0511 - acc: 0.9853\n",
      "Epoch 94/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0147 - acc: 1.000 - ETA: 0s - loss: 0.0344 - acc: 1.000 - ETA: 0s - loss: 0.0411 - acc: 0.990 - ETA: 0s - loss: 0.0446 - acc: 0.989 - 0s 250us/sample - loss: 0.0449 - acc: 0.9889\n",
      "Epoch 95/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0337 - acc: 1.000 - ETA: 0s - loss: 0.0429 - acc: 0.989 - ETA: 0s - loss: 0.0509 - acc: 0.983 - ETA: 0s - loss: 0.0506 - acc: 0.982 - 0s 225us/sample - loss: 0.0500 - acc: 0.9828\n",
      "Epoch 96/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0175 - acc: 1.000 - ETA: 0s - loss: 0.0325 - acc: 0.984 - ETA: 0s - loss: 0.0423 - acc: 0.983 - ETA: 0s - loss: 0.0356 - acc: 0.986 - ETA: 0s - loss: 0.0403 - acc: 0.986 - 0s 287us/sample - loss: 0.0400 - acc: 0.9865\n",
      "Epoch 97/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0607 - acc: 1.000 - ETA: 0s - loss: 0.0231 - acc: 1.000 - ETA: 0s - loss: 0.0358 - acc: 0.991 - ETA: 0s - loss: 0.0423 - acc: 0.988 - 0s 253us/sample - loss: 0.0408 - acc: 0.9889\n",
      "Epoch 98/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0775 - acc: 0.968 - ETA: 0s - loss: 0.0420 - acc: 0.984 - ETA: 0s - loss: 0.0410 - acc: 0.984 - ETA: 0s - loss: 0.0487 - acc: 0.984 - 0s 279us/sample - loss: 0.0463 - acc: 0.9877\n",
      "Epoch 99/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0199 - acc: 1.000 - ETA: 0s - loss: 0.0292 - acc: 0.992 - ETA: 0s - loss: 0.0335 - acc: 0.991 - ETA: 0s - loss: 0.0374 - acc: 0.991 - 0s 239us/sample - loss: 0.0355 - acc: 0.9926\n",
      "Epoch 100/100\n",
      "814/814 [==============================] - ETA: 0s - loss: 0.0216 - acc: 1.000 - ETA: 0s - loss: 0.0433 - acc: 0.989 - ETA: 0s - loss: 0.0417 - acc: 0.987 - ETA: 0s - loss: 0.0463 - acc: 0.987 - 0s 249us/sample - loss: 0.0459 - acc: 0.9877\n"
     ]
    }
   ],
   "source": [
    "#action generation\n",
    "def train_dialogue(domain_file='data/domain.yml',\n",
    "    model_path='./models/dialogue',\n",
    "    training_data_file='data/stories.md'):\n",
    "    agent = Agent(domain_file, policies=[MemoizationPolicy(), KerasPolicy()])\n",
    "    data = agent.load_data(training_data_file)\n",
    "    agent.train(data)\n",
    "    agent.persist(model_path)\n",
    "    return agent\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level='ERROR')\n",
    "    train_dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "hi\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! What can I do for you?\n",
      "vaccancy\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry i didn't get you \n",
      "job\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy to have helped you!\n",
      "Talk to you later.\n",
      "any job vaccancy\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you looking for a technical or a business role?\n",
      "technical\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n",
      "ERROR:rasa_core.processor:Encountered an exception while running action 'action_check_positions'. Bot will continue, but the actions events are lost. Make sure to fix the exception in your custom code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you can apply in data science , machine learning , app developdment , web development\n",
      "contact xyz@gmail.com\n",
      "Do you want more help?\n",
      "yes\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is it that I can help you with? Open position or check you application status\n",
      "open positions\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you looking for a technical or a business role?\n",
      "bussiness\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry i didn't get you \n",
      "bye\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/nlu/new/default/recruitment\\component_5_EmbeddingIntentClassifier.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a nice day\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "import numpy as np\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a=input()\n",
    "    if a=='stop':\n",
    "        break\n",
    "   \n",
    "    nlu_interpreter = RasaNLUInterpreter('./models/nlu/new/default/recruitment')\n",
    "    b=nlu_interpreter.parse(a)\n",
    "    if b['intent']['confidence'] < 0.30 :\n",
    "        print(\"Sorry i didn't get you \")\n",
    "        continue\n",
    "    \n",
    "    agent = Agent.load(\"models/dialogue\", interpreter= nlu_interpreter)\n",
    "    ans = agent.handle_text(a)\n",
    "    for i in range(np.size(ans)):\n",
    "        print(ans[i]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasa123",
   "language": "python",
   "name": "rasa123"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
